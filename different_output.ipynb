{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will try saving everything in one file such that i dont have to open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6290,
     "status": "ok",
     "timestamp": 1629797165470,
     "user": {
      "displayName": "Fabio PÃ¶schko",
      "photoUrl": "",
      "userId": "12121821188507889824"
     },
     "user_tz": -120
    },
    "id": "qWoAsn4MHQyk"
   },
   "outputs": [],
   "source": [
    "from architectures import *\n",
    "from dataset_numpy import *\n",
    "from utils import *\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import json\n",
    "import h5py\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "\n",
    "#getting the configurations from the config file\n",
    "with open('working_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "testset = RandomSeqDataset(config[\"dataset_path\"],config[\"testset_key\"])\n",
    "trainset = RandomSeqDataset(config[\"dataset_path\"],config[\"trainset_key\"])\n",
    "\n",
    "\n",
    "# Create dataloaders from each subset\n",
    "test_loader = DataLoader(testset,  # we want to load our dataset\n",
    "                         shuffle=False,  # shuffle for training\n",
    "                         batch_size=1,  # 1 sample at a time\n",
    "                         num_workers=0,\n",
    "                         collate_fn=stack_if_possible_collate_fn  # no background workers\n",
    "                         )\n",
    "\n",
    "training_loader = DataLoader(trainset,  # we want to load our dataset\n",
    "                             shuffle=False,  # shuffle for training\n",
    "                             batch_size=4,  # stack 4 samples to a minibatch\n",
    "                             num_workers=0,\n",
    "                             collate_fn=stack_if_possible_collate_fn  # 2 background workers\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_CNN(\n",
       "  (encoder_linear1): Linear(in_features=8100, out_features=6400, bias=True)\n",
       "  (encoder_linear2): Linear(in_features=6400, out_features=4900, bias=True)\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (15): ReLU()\n",
       "    (16): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (17): ReLU()\n",
       "    (18): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (19): ReLU()\n",
       "    (20): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (21): ReLU()\n",
       "  )\n",
       "  (output_layer): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (decoder_linear1): Linear(in_features=4900, out_features=6400, bias=True)\n",
       "  (decoder_linear2): Linear(in_features=6400, out_features=8100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AE_CNN(nn.Module):\n",
    "    def __init__(self, ae_input_dim = 90*90, ae_middle_dim = 80*80, ae_hidden_dim = 70*70,\n",
    "                n_input_channels = 1, n_output_channels = 1, conv_kernel_size = 5, n_hidden_layers=5, n_hidden_kernels=32):\n",
    "        super(AE_CNN, self).__init__()\n",
    "        # encoder\n",
    "        self.encoder_linear1 = nn.Linear(ae_input_dim, ae_middle_dim)\n",
    "        self.encoder_linear2 = nn.Linear(ae_middle_dim, ae_hidden_dim)\n",
    "        \n",
    "        # convolution\n",
    "        hidden_layers = []\n",
    "        for _ in range(n_hidden_layers):\n",
    "            # Add a CNN layer\n",
    "            layer = nn.Conv2d(in_channels=n_input_channels,\n",
    "                              out_channels=n_hidden_kernels,\n",
    "                              kernel_size=conv_kernel_size)\n",
    "            hidden_layers.append(layer)\n",
    "            # Add relu activation module to list of modules\n",
    "            hidden_layers.append(nn.ReLU())\n",
    "            n_input_channels = n_hidden_kernels\n",
    "\n",
    "        # deconvolution\n",
    "        for _ in range(n_hidden_layers + 1):\n",
    "            # Add a CNN layer\n",
    "            layer = nn.ConvTranspose2d(in_channels=n_input_channels,\n",
    "                                       out_channels=n_hidden_kernels,\n",
    "                                       kernel_size=conv_kernel_size)\n",
    "            hidden_layers.append(layer)\n",
    "            # Add relu activation module to list of modules\n",
    "            hidden_layers.append(nn.ReLU())\n",
    "            n_input_channels = n_hidden_kernels\n",
    "\n",
    "            \n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "        self.output_layer = nn.Conv2d(in_channels=n_input_channels,\n",
    "                                      out_channels=n_output_channels,\n",
    "                                      kernel_size=conv_kernel_size)\n",
    "\n",
    "        \n",
    "        # decoder\n",
    "        self.decoder_linear1 = nn.Linear(ae_hidden_dim, ae_middle_dim)\n",
    "        self.decoder_linear2 = nn.Linear(ae_middle_dim, ae_input_dim)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = self.encoder_linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.encoder_linear2(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = self.decoder_linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.decoder_linear2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    #def create_outputs(self,x,known_array):\n",
    "    #    output = []\n",
    "    #    for i in range(4):\n",
    "    #        output.append(x[i][known_array[i]==0])\n",
    "    #    return output\n",
    "    \n",
    "    def create_outputs(self,x,known_array):\n",
    "        return x[known_array==0]\n",
    "\n",
    "    def forward(self, x, known_array):\n",
    "        x = x.view(-1,1,90*90)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1,1,70,70)\n",
    "        \n",
    "         # Apply hidden layers module\n",
    "        x = self.hidden_layers(x)\n",
    "\n",
    "        # Apply last layer (=output layer)\n",
    "        x = self.output_layer(x)\n",
    "        x = x.view(-1,1,70*70)\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(-1,1,90,90)\n",
    "        x=F.sigmoid(x)\n",
    "        return self.create_outputs(x,known_array)\n",
    "\n",
    "net = AE_CNN()\n",
    "#torch.save(net, os.path.join(config[\"results_path\"], \"train.pt\"))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing the training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\nn\\functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "ic| loss: tensor(0.0695, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0671, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0837, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0515, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0783, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0644, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0888, grad_fn=<MseLossBackward>)\n",
      "  0%|          | 0/100 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d576c85f63c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Preform the update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[1;31m# Reset the accumulated gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    108\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             F.sgd(params_with_grad,\n\u001b[0m\u001b[0;32m    111\u001b[0m                   \u001b[0md_p_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                   \u001b[0mmomentum_buffer_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create an instance of our NET\n",
    "#net = torch.load(os.path.join(\"results\", \"train.pt\"))\n",
    "\n",
    "# GPU will be much faster here\n",
    "device = torch.device(config[\"device\"])\n",
    "net.to(device=device)\n",
    "\n",
    "# also try rmse and absolute error\n",
    "loss_function = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# Use a SGD optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-1)\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=config[\"learningrate\"])\n",
    "\n",
    "# Define a tensorboard summary writer that writes to directory \"results_path/tensorboard\"\n",
    "writer = SummaryWriter(log_dir=os.path.join(config[\"results_path\"], 'tensorboard'), flush_secs=1)\n",
    "\n",
    "best_loss = np.float(\"inf\")\n",
    "# Optimize our dsnn model using SGD:\n",
    "print(\"Continuing the training:\")\n",
    "\n",
    "# for update in tqdm(range(200)):\n",
    "with tqdm(total=config[\"n_updates\"]) as pbar:\n",
    "    for update in range(config[\"n_updates\"]):\n",
    "        x = 0\n",
    "        for data in training_loader:\n",
    "            # Compute the output\n",
    "            input_array, known_array, target_array = data\n",
    "            #ic(target_array)\n",
    "            # ic(input_array.unsqueeze(1).type(torch.float32).shape)\n",
    "            #ic(input_array.unsqueeze(1).type(torch.float32).shape)\n",
    "            output = net(input_array.unsqueeze(1).type(torch.float32),known_array.unsqueeze(1).type(torch.float32))\n",
    "            #ic(output[300])\n",
    "            # Compute the loss\n",
    "            new_target = torch.tensor(np.concatenate(target_array, axis = None))\n",
    "            #ic(output, target_array)\n",
    "            #loss = 0\n",
    "            #for target,out in zip(target_array,output):\n",
    "                #loss+= loss_function(out, target)\n",
    "            loss = loss_function(output.type(torch.float32), new_target.type(torch.float32))\n",
    "            #loss = torch.mean((output-new_target)**2)\n",
    "            ic(loss)\n",
    "            # Compute the gradients\n",
    "            loss.backward()\n",
    "            # Preform the update\n",
    "            optimizer.step()\n",
    "            # Reset the accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            x += 1\n",
    "            if x == 1000:\n",
    "                break\n",
    "\n",
    "        # automatic saving of the best model\n",
    "        if update % 1 == 0:\n",
    "            with torch.no_grad():\n",
    "                y = 0\n",
    "                sum_loss = 0\n",
    "                for tdata in test_loader:\n",
    "                    input_array, known_array, target_array = data\n",
    "                    output = net(input_array.unsqueeze(1).type(torch.float32),known_array.unsqueeze(1).type(torch.float32))\n",
    "                    new_target = torch.tensor(np.concatenate(target_array, axis = None))\n",
    "                    #ic(output.shape, new_target.shape)\n",
    "                    sum_loss += loss_function(output, new_target.type(torch.float32))\n",
    "                    y += 1\n",
    "                    if y == 1:\n",
    "                        ic(sum_loss)\n",
    "                        break\n",
    "                    \n",
    "            #if sum_loss < best_loss:\n",
    "            #  #  torch.save(net, os.path.join(config[\"results_path\"], \"autosave\", f\"loss_{sum_loss}.pt\"))\n",
    "            #    best_loss = loss\n",
    "\n",
    "        # Tensorboard\n",
    "        #if update % 1 == 0:\n",
    "        #    # Add losse as scalars to tensorboard\n",
    "        #    writer.add_scalar(tag=\"training/loss\", scalar_value=sum_loss,\n",
    "        #                      global_step=update)\n",
    "#\n",
    "        #    # Add images to Tensorboard\n",
    "        #    writer.add_image(tag=\"training/output\", img_tensor=output[0], global_step=update)\n",
    "#\n",
    "        #    writer.add_image(tag=\"training/input\", img_tensor=(original.unsqueeze(1)[0]), global_step=update)\n",
    "\n",
    "        torch.save(net, os.path.join(config[\"results_path\"], \"train.pt\"))\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"training finished\")\n",
    "#torch.save(net, os.path.join(config[\"results_path\"], \"my_model_A.pt\"))\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "#open the testfile\n",
    "import pickle\n",
    "import os\n",
    "with open(os.path.join('data','testset.pkl'), 'rb') as pickle_file:\n",
    "    arrays = pickle.load(pickle_file)\n",
    "len(arrays['input_arrays'])\n",
    "\n",
    "model = net\n",
    "#creating the predictions\n",
    "predictions_server = []\n",
    "for i in range(len(arrays['input_arrays'])):\n",
    "    inp = arrays['input_arrays'][i].reshape(1,90,90)\n",
    "    known = arrays['known_arrays'][i].reshape(1,1,1,90,90)\n",
    "    #ic(inp.shape,known.shape)\n",
    "    out = model(torch.tensor(inp,dtype = torch.float32)/255,known)\n",
    "    #ic(out.shape)\n",
    "    pred=out.detach().numpy()\n",
    "    predictions_server.append(np.array(pred*255,dtype=np.uint8 ))\n",
    "    \n",
    "with open(os.path.join('data','testset_submission_does_not_train_ae_convolution.pkl'), 'wb') as pickle_file:\n",
    "    pickle.dump(predictions_server, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8),\n",
       " array([127, 126, 127, ..., 127, 127, 127], dtype=uint8)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open the testfile\n",
    "import pickle\n",
    "import os\n",
    "with open(os.path.join('data','testset_submission_does_not_train_ae_convolution.pkl'), 'rb') as pickle_file:\n",
    "    convolution = pickle.load(pickle_file)\n",
    "convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "<>:1: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "<ipython-input-34-493eabe09421>:1: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "  1()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-493eabe09421>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| loss: tensor(0.0486, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0564, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0605, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0427, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0341, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0420, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.1100, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0360, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0832, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0861, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0656, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0972, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0687, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0692, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0279, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0344, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0381, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0476, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0693, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0481, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0306, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0402, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0672, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0398, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0478, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0628, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0463, grad_fn=<MseLossBackward>)\n",
      "ic| loss: tensor(0.0673, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The first input argument needs to be a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b23e01c14f61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Compute the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnew_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m#ic(output.shape, new_target.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The first input argument needs to be a sequence"
     ]
    }
   ],
   "source": [
    "# also try rmse and absolute error\n",
    "loss_function = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# Use a SGD optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-7)\n",
    "\n",
    "for data in training_loader:\n",
    "    input_array, known_array, target_array = data\n",
    "    #ic(target_array)\n",
    "    # ic(input_array.unsqueeze(1).type(torch.float32).shape)\n",
    "    #ic(input_array.unsqueeze(1).type(torch.float32).shape)\n",
    "    output = net(input_array.unsqueeze(1).type(torch.float32),known_array.unsqueeze(1).type(torch.float32))\n",
    "    \n",
    "    # Compute the loss\n",
    "    new_target = torch.tensor(np.concatenate(target_array, axis = None))\n",
    "    #ic(output.shape, new_target.shape)\n",
    "    loss = loss_function(output, new_target.type(torch.float32))\n",
    "    ic(loss)\n",
    "    # Compute the gradients\n",
    "    loss.backward()\n",
    "    # Preform the update\n",
    "    optimizer.step()\n",
    "    # Reset the accumulated gradients\n",
    "    optimizer.zero_grad()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9137"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=0\n",
    "for array in target_array:\n",
    "    for element in array:\n",
    "        x+=1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2171"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 0\n",
    "for element in output:\n",
    "    for e in element:\n",
    "        y+=1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9296"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 7\n",
    "(x*90*2+x*(90-2*x)*2)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2916"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 9\n",
    "90*90-(90-2*x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2171])\n"
     ]
    }
   ],
   "source": [
    "for e in output:\n",
    "    print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2, 1, 3, 4, 0],\n",
       "          [2, 6, 2, 3, 1],\n",
       "          [6, 3, 2, 8, 0],\n",
       "          [5, 2, 7, 3, 4],\n",
       "          [5, 2, 0, 0, 1]]],\n",
       "\n",
       "\n",
       "        [[[2, 4, 4, 2, 0],\n",
       "          [5, 4, 5, 2, 4],\n",
       "          [3, 6, 4, 6, 0],\n",
       "          [1, 3, 2, 0, 4],\n",
       "          [5, 1, 4, 6, 6]]],\n",
       "\n",
       "\n",
       "        [[[0, 5, 5, 2, 5],\n",
       "          [4, 0, 0, 7, 8],\n",
       "          [0, 8, 5, 8, 5],\n",
       "          [2, 2, 4, 6, 4],\n",
       "          [7, 0, 3, 3, 8]]],\n",
       "\n",
       "\n",
       "        [[[3, 7, 2, 7, 3],\n",
       "          [7, 7, 5, 1, 2],\n",
       "          [1, 7, 2, 0, 5],\n",
       "          [5, 6, 3, 7, 6],\n",
       "          [8, 2, 4, 8, 7]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(np.random.randint(0,9,(4,1,5,5)))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 0, 1, 0],\n",
       "          [1, 0, 1, 1, 1],\n",
       "          [1, 0, 1, 1, 0],\n",
       "          [0, 1, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 1]]],\n",
       "\n",
       "\n",
       "        [[[0, 0, 0, 1, 0],\n",
       "          [1, 1, 0, 0, 0],\n",
       "          [1, 1, 0, 0, 1],\n",
       "          [0, 0, 0, 1, 1],\n",
       "          [1, 1, 0, 0, 1]]],\n",
       "\n",
       "\n",
       "        [[[0, 0, 0, 1, 0],\n",
       "          [0, 0, 0, 1, 1],\n",
       "          [1, 1, 1, 1, 1],\n",
       "          [0, 1, 1, 0, 0],\n",
       "          [1, 0, 0, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[1, 0, 1, 1, 0],\n",
       "          [1, 1, 0, 1, 0],\n",
       "          [1, 1, 0, 1, 0],\n",
       "          [0, 1, 1, 1, 0],\n",
       "          [0, 0, 0, 1, 1]]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(np.random.randint(0,2,(4,1,5,5)))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([3, 0, 6, 3, 0, 5, 7, 3, 4, 5, 0, 0], dtype=torch.int32),\n",
       " tensor([2, 4, 4, 0, 5, 2, 4, 4, 6, 1, 3, 2, 4, 6], dtype=torch.int32),\n",
       " tensor([0, 5, 5, 5, 4, 0, 0, 2, 6, 4, 0, 3], dtype=torch.int32),\n",
       " tensor([7, 3, 5, 2, 2, 5, 5, 6, 8, 2, 4], dtype=torch.int32)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "for i in range(4):\n",
    "    output.append(x[i][y[i]==0])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-3d761cc23703>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmask2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmask3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "mask0 = x[0][y[0]==0]\n",
    "mask1 = x[1][y[1]==0]\n",
    "mask2 = x[2][y[2]==0]\n",
    "mask3 = x[3][y[3]==0]\n",
    "mask = [mask0,mask1,mask2,mask3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 5])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_CNN(\n",
       "  (encoder_linear1): Linear(in_features=8100, out_features=6400, bias=True)\n",
       "  (encoder_linear2): Linear(in_features=6400, out_features=4900, bias=True)\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (15): ReLU()\n",
       "    (16): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (17): ReLU()\n",
       "    (18): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (19): ReLU()\n",
       "    (20): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (21): ReLU()\n",
       "  )\n",
       "  (output_layer): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (decoder_linear1): Linear(in_features=4900, out_features=6400, bias=True)\n",
       "  (decoder_linear2): Linear(in_features=6400, out_features=8100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net = AE_CNN()\n",
    "torch.save(net, os.path.join(config[\"results_path\"], \"AE_CNN_model1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "executionInfo": {
     "elapsed": 329701,
     "status": "error",
     "timestamp": 1629797771025,
     "user": {
      "displayName": "Fabio PÃ¶schko",
      "photoUrl": "",
      "userId": "12121821188507889824"
     },
     "user_tz": -120
    },
    "id": "MbPtIOqzLK4u",
    "outputId": "3aed9de1-95c0-4e9f-85d4-a21127d7c6b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]ic| output[0]: tensor([[[0.0157, 0.0150, 0.0188,  ..., 0.0149, 0.0121, 0.0138],\n",
      "                        [0.0174, 0.0151, 0.0244,  ..., 0.0200, 0.0239, 0.0171],\n",
      "                        [0.0127, 0.0126, 0.0144,  ..., 0.0102, 0.0191, 0.0141],\n",
      "                        ...,\n",
      "                        [0.0196, 0.0172, 0.0150,  ..., 0.0161, 0.0213, 0.0153],\n",
      "                        [0.0231, 0.0172, 0.0292,  ..., 0.0288, 0.0119, 0.0120],\n",
      "                        [0.0120, 0.0255, 0.0167,  ..., 0.0171, 0.0148, 0.0195]]],\n",
      "                      grad_fn=<SelectBackward>)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing the training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-71e757574a7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m# Compute the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[1;31m# Compute the gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "# Create an instance of our NET\n",
    "net = torch.load(os.path.join(\"results\", \"my_model_A.pt\"))\n",
    "\n",
    "# GPU will be much faster here\n",
    "device = torch.device(config[\"device\"])\n",
    "net.to(device=device)\n",
    "\n",
    "# also try rmse and absolute error\n",
    "loss_function = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# Use a SGD optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-2)\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=config[\"learningrate\"])\n",
    "\n",
    "# Define a tensorboard summary writer that writes to directory \"results_path/tensorboard\"\n",
    "writer = SummaryWriter(log_dir=os.path.join(config[\"results_path\"], 'tensorboard'), flush_secs=1)\n",
    "\n",
    "best_loss = np.float(\"inf\")\n",
    "# Optimize our dsnn model using SGD:\n",
    "print(\"Continuing the training:\")\n",
    "\n",
    "# for update in tqdm(range(200)):\n",
    "with tqdm(total=config[\"n_updates\"]) as pbar:\n",
    "    for update in range(config[\"n_updates\"]):\n",
    "        x = 0\n",
    "        for data in training_loader:\n",
    "            # Compute the output\n",
    "            input_array, known_array, target = data\n",
    "            # ic(input_array.unsqueeze(1).type(torch.float32).shape)\n",
    "            output = net(input_array.unsqueeze(1).type(torch.float32))\n",
    "\n",
    "            # Compute the loss\n",
    "            ic(output[0])\n",
    "            loss = loss_function(output, target.type(torch.float32).unsqueeze(1))\n",
    "            # Compute the gradients\n",
    "            loss.backward()\n",
    "            # Preform the update\n",
    "            optimizer.step()\n",
    "            # Reset the accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            x += 1\n",
    "            if x == 10:\n",
    "                break\n",
    "\n",
    "        # automatic saving of the best model\n",
    "        if update % 1 == 0:\n",
    "            with torch.no_grad():\n",
    "                y = 0\n",
    "                sum_loss = 0\n",
    "                for tdata in test_loader:\n",
    "                    input_array, known_array, target_array = data\n",
    "                    output = net(input_array.unsqueeze(1).type(torch.float32))\n",
    "                    sum_loss += loss_function(output, original.type(torch.float32).unsqueeze(1))\n",
    "                    y += 1\n",
    "                    if y == 10:\n",
    "                        ic(sum_loss)\n",
    "                        break\n",
    "                    \n",
    "            #if sum_loss < best_loss:\n",
    "            #  #  torch.save(net, os.path.join(config[\"results_path\"], \"autosave\", f\"loss_{sum_loss}.pt\"))\n",
    "            #    best_loss = loss\n",
    "\n",
    "        # Tensorboard\n",
    "        #if update % 1 == 0:\n",
    "        #    # Add losse as scalars to tensorboard\n",
    "        #    writer.add_scalar(tag=\"training/loss\", scalar_value=sum_loss,\n",
    "        #                      global_step=update)\n",
    "#\n",
    "        #    # Add images to Tensorboard\n",
    "        #    writer.add_image(tag=\"training/output\", img_tensor=output[0], global_step=update)\n",
    "#\n",
    "        #    writer.add_image(tag=\"training/input\", img_tensor=(original.unsqueeze(1)[0]), global_step=update)\n",
    "\n",
    "        #torch.save(net, os.path.join(config[\"results_path\"], \"train.pt\"))\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"training finished\")\n",
    "#torch.save(net, os.path.join(config[\"results_path\"], \"my_model_A.pt\"))\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "110 sec with cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td7u-scYLYRg"
   },
   "source": [
    "note to myself:\n",
    "activate tensorboard like this:\n",
    "\n",
    "activate programing_in_python_2\n",
    "tensorboard --logdir=C:\\Users\\fabio\\Google_Drive\\AI_Studium\\programing_python\\ass2\\ex5\\results\\tensorboard\n",
    "\n",
    "http://localhost:6006/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCiAwi3ILK-0"
   },
   "outputs": [],
   "source": [
    "len(training_loader)/100*112/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3HiO8l_GLLB7"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def array_to_img(image):\n",
    "    img = Image.fromarray(image,)\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "X-E-cAS-LLEs"
   },
   "outputs": [],
   "source": [
    "for data in test_loader:\n",
    "    image,_ = data\n",
    "    array_to_img(np.array(image)[0].reshape(90,90)*255)\n",
    "    array_to_img(np.array(_)[0].reshape(90,90)*255)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hD5HJM3qKQfB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hsv3SsxNKQht"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10362,
     "status": "ok",
     "timestamp": 1629797789195,
     "user": {
      "displayName": "Fabio PÃ¶schko",
      "photoUrl": "",
      "userId": "12121821188507889824"
     },
     "user_tz": -120
    },
    "id": "L3iO5U7yHQyo",
    "outputId": "db8b1d2c-d27f-4b01-e9b8-9ee124f296ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All changes made in this colab session should now be visible in Drive.\n"
     ]
    }
   ],
   "source": [
    "drive.flush_and_unmount()\n",
    "print('All changes made in this colab session should now be visible in Drive.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZi8BOmhHQyp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsND93NMHQyq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab_final_predictions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

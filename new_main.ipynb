{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8517cba7-d1c6-4f04-b42e-4fa1a04247c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import *\n",
    "from dataset_numpy import *\n",
    "from utils import *\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baea79f6-eb62-4596-bb8f-7622568fa981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the configurations from the config file\n",
    "with open('working_config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a732d58-89b0-4144-80bd-8302a9069128",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = RandomSeqDataset(r\"D:\\studium_tests\\small_original_dataset2.npz\",config[\"testset_key\"],cuda=False)\n",
    "trainset = RandomSeqDataset(r\"D:\\studium_tests\\small_original_dataset2.npz\",config[\"trainset_key\"],cuda = False)\n",
    "\n",
    "\n",
    "# Create dataloaders from each subset\n",
    "test_loader = DataLoader(testset,  # we want to load our dataset\n",
    "                         shuffle=False,  # shuffle for training\n",
    "                         batch_size=1,  # 1 sample at a time\n",
    "                         num_workers=0,\n",
    "                         collate_fn=stack_if_possible_collate_fn  # no background workers\n",
    "                         )\n",
    "\n",
    "training_loader = DataLoader(trainset,  # we want to load our dataset\n",
    "                             shuffle=False,  # shuffle for training\n",
    "                             batch_size=4,  # stack 4 samples to a minibatch\n",
    "                             num_workers=0,\n",
    "                             collate_fn=stack_if_possible_collate_fn  # 2 background workers\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e7b0489-dfbb-477f-b22e-bc9a50741472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#claring some folders\n",
    "for key in config[\"to_clear\"]:\n",
    "    clear_folder(config[\"to_clear\"][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252f9dcd-1884-47bd-827c-2f3177553345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_input_channels: int, n_hidden_layers: int,\n",
    "                 n_hidden_kernels: int, n_output_channels: int):\n",
    "        \"\"\"CNN, consisting of `n_hidden_layers` linear layers, using relu\n",
    "        activation function in the hidden CNN layers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_input_channels: int\n",
    "            Number of features channels in input tensor\n",
    "        n_hidden_layers: int\n",
    "            Number of hidden layers\n",
    "        n_hidden_kernels: int\n",
    "            Number of kernels in each hidden layer\n",
    "        n_output_channels: int\n",
    "            Number of features in output tensor\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        hidden_layers = []\n",
    "        for _ in range(n_hidden_layers):\n",
    "            # Add a CNN layer\n",
    "            layer = nn.Conv2d(in_channels=n_input_channels,\n",
    "                              out_channels=n_hidden_kernels,\n",
    "                              kernel_size=7)\n",
    "            hidden_layers.append(layer)\n",
    "            # Add relu activation module to list of modules\n",
    "            hidden_layers.append(nn.ReLU())\n",
    "            n_input_channels = n_hidden_kernels\n",
    "\n",
    "        # decoder\n",
    "        for _ in range(n_hidden_layers + 1):\n",
    "            # Add a CNN layer\n",
    "            layer = nn.ConvTranspose2d(in_channels=n_input_channels,\n",
    "                                       out_channels=n_hidden_kernels,\n",
    "                                       kernel_size=7)\n",
    "            hidden_layers.append(layer)\n",
    "            # Add relu activation module to list of modules\n",
    "            hidden_layers.append(nn.ReLU())\n",
    "            n_input_channels = n_hidden_kernels\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "        self.output_layer = nn.Conv2d(in_channels=n_input_channels,\n",
    "                                      out_channels=n_output_channels,\n",
    "                                      kernel_size=7)\n",
    "        self.linear1 = nn.Linear(90*90, 90*90)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply CNN to `x`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.tensor\n",
    "            Input tensor of shape (n_samples, n_input_channels, x, y)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        torch.tensor\n",
    "            Output tensor of shape (n_samples, n_output_channels, u, v)\n",
    "        \"\"\"\n",
    "        # Apply hidden layers module\n",
    "        hidden_features = self.hidden_layers(x)\n",
    "\n",
    "        # Apply last layer (=output layer)\n",
    "        output = self.output_layer(hidden_features)\n",
    "        output = x.view(-1,1,90*90)\n",
    "        output = self.linear1(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.view(-1,1,90,90)\n",
    "        return output\n",
    "\n",
    "net = CNN(n_input_channels=config[\"network_config\"][\"n_input_channels\"], n_hidden_layers=config[\"network_config\"][\"n_hidden_layers\"], n_hidden_kernels=config[\"network_config\"][\"n_hidden_kernels\"],\n",
    "          n_output_channels=config[\"network_config\"][\"n_output_channels\"])\n",
    "torch.save(net, os.path.join(config[\"results_path\"], \"my_pc_cnn.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0ef8533-4ed3-4664-b7b6-41f3fc6d5caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing the training:\n",
      "tensor(0.9897)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [06:55<11:25:15, 415.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9549)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [14:04<11:31:58, 423.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [21:18<11:32:35, 428.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [28:19<11:20:43, 425.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8921)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [35:17<11:09:04, 422.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [48:45<12:43:59, 487.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-916297e747d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m# ic(input_array.unsqueeze(1).type(torch.float32).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m# Compute the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-81e93e2eb272>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \"\"\"\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# Apply hidden layers module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mhidden_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# Apply last layer (=output layer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\programing_in_python_2\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    914\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m         return F.conv_transpose2d(\n\u001b[0m\u001b[0;32m    917\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create an instance of our CNN\n",
    "cnn = torch.load(os.path.join(config[\"results_path\"], \"my_pc_cnn.pt\"))\n",
    "\n",
    "# GPU will be much faster here\n",
    "device = torch.device(config[\"device\"])\n",
    "#device = torch.device(\"cpu\")\n",
    "cnn.to(device=device)\n",
    "\n",
    "# also try rmse and absolute error\n",
    "loss_function = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# Use a SGD optimizer\n",
    "#optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-4)\n",
    "\n",
    "# Define a tensorboard summary writer that writes to directory \"results_path/tensorboard\"\n",
    "writer = SummaryWriter(log_dir=os.path.join(config[\"results_path\"], 'tensorboard'), flush_secs=1)\n",
    "\n",
    "best_loss = np.float(\"inf\")\n",
    "# Optimize our dsnn model using SGD:\n",
    "print(\"Continuing the training:\")\n",
    "\n",
    "#print(f\"cnn: {cnn.device}\")\n",
    "# for update in tqdm(range(200)):\n",
    "with tqdm(total=config[\"n_updates\"]) as pbar:\n",
    "    for update in range(config[\"n_updates\"]):\n",
    "        x = 0\n",
    "        for data in training_loader:\n",
    "            # Compute the output\n",
    "            input_array,  original = data\n",
    "\n",
    "            # ic(input_array.unsqueeze(1).type(torch.float32).shape)\n",
    "            output = cnn(input_array.unsqueeze(1).type(torch.float32))\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_function(output, original.type(torch.float32).unsqueeze(1))\n",
    "            # Compute the gradients\n",
    "            loss.backward()\n",
    "            # Preform the update\n",
    "            optimizer.step()\n",
    "            # Reset the accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            x += 1\n",
    "            if x == 500:\n",
    "                break\n",
    "\n",
    "        # automatic saving of the best model\n",
    "        if update % 1 == 0:\n",
    "            with torch.no_grad():\n",
    "                y = 0\n",
    "                sum_loss = 0\n",
    "                for tdata in test_loader:\n",
    "                    input_array, original = data\n",
    "\n",
    "                    output = cnn(input_array.unsqueeze(1).type(torch.float32))\n",
    "                    sum_loss += loss_function(output, original.type(torch.float32).unsqueeze(1))\n",
    "                    y += 1\n",
    "                    if y == 50:\n",
    "                        print(sum_loss)\n",
    "                        break\n",
    "                    \n",
    "            if sum_loss < best_loss:\n",
    "                torch.save(cnn, os.path.join(config[\"results_path\"], \"autosave\", f\"loss_{sum_loss}.pt\"))\n",
    "                best_loss = loss\n",
    "\n",
    "        # Tensorboard\n",
    "        if update % 1 == 0:\n",
    "            # Add losse as scalars to tensorboard\n",
    "            writer.add_scalar(tag=\"training/loss\", scalar_value=sum_loss,\n",
    "                              global_step=update)\n",
    "\n",
    "            # Add images to Tensorboard\n",
    "            writer.add_image(tag=\"training/output\", img_tensor=output[0], global_step=update)\n",
    "\n",
    "            writer.add_image(tag=\"training/input\", img_tensor=(original.unsqueeze(1)[0]), global_step=update)\n",
    "\n",
    "        torch.save(cnn, os.path.join(config[\"results_path\"], \"my_pc_cnn.pt\"))\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15ca1047-d580-4518-bb39-38171d8a6ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054c451-f36a-4be9-8410-9c67761ab2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cefd2c-353d-43df-af8c-5fe2f29f40ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9938c-f13b-438f-8447-ab629ccf07c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c374a8-3a89-4c7f-86e1-3c8c4a1d47d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276185b5-24e1-4f7a-80c2-4581055a7dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
